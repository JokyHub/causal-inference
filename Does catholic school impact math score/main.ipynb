{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOES ATTENDING CATHOLIC SCHOOL HELP IMPROVE MATHS SCORE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this notebook is to introduce the notion of confounders in causal inference and provide a way to control them in a causal effect estimation.\n",
    "\n",
    "We delve into a longitudinal study carried out by the University of Michigan to understand whether catholic/private schools are more beneficial for the student's math education. For more information: https://www.icpsr.umich.edu/web/ICPSR/studies/4075."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install skimpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U -q statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from skimpy import skim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>childid</th>\n",
       "      <th>catholic</th>\n",
       "      <th>race</th>\n",
       "      <th>race_white</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_hispanic</th>\n",
       "      <th>race_asian</th>\n",
       "      <th>NumPlace</th>\n",
       "      <th>Age_Mom</th>\n",
       "      <th>Age_Dad</th>\n",
       "      <th>...</th>\n",
       "      <th>BelowHighSchool_Dad</th>\n",
       "      <th>BelowHighSchool_Mom</th>\n",
       "      <th>JobScore_Mom</th>\n",
       "      <th>JobScore_Dad</th>\n",
       "      <th>IncomeCat</th>\n",
       "      <th>Income</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>FoodStamp</th>\n",
       "      <th>Score_t</th>\n",
       "      <th>Score_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001002C</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE, NON-HISPANIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>77.5</td>\n",
       "      <td>$50,001 TO $75,000</td>\n",
       "      <td>62500.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.043</td>\n",
       "      <td>0.981753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001004C</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE, NON-HISPANIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.95</td>\n",
       "      <td>53.5</td>\n",
       "      <td>$40,001 TO $50,000</td>\n",
       "      <td>45000.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.280</td>\n",
       "      <td>0.594378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001005C</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE, NON-HISPANIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.791</td>\n",
       "      <td>0.338152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001010C</td>\n",
       "      <td>0</td>\n",
       "      <td>WHITE, NON-HISPANIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.43</td>\n",
       "      <td>53.5</td>\n",
       "      <td>$50,001 TO $75,000</td>\n",
       "      <td>62500.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.272</td>\n",
       "      <td>0.490611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001011C</td>\n",
       "      <td>1</td>\n",
       "      <td>WHITE, NON-HISPANIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.50</td>\n",
       "      <td>53.5</td>\n",
       "      <td>$75,001 TO $100,000</td>\n",
       "      <td>87500.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.604</td>\n",
       "      <td>1.451278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    childid  catholic                 race  race_white  race_black  \\\n",
       "0  0001002C         0  WHITE, NON-HISPANIC           1           0   \n",
       "1  0001004C         0  WHITE, NON-HISPANIC           1           0   \n",
       "2  0001005C         0  WHITE, NON-HISPANIC           1           0   \n",
       "3  0001010C         0  WHITE, NON-HISPANIC           1           0   \n",
       "4  0001011C         1  WHITE, NON-HISPANIC           1           0   \n",
       "\n",
       "   race_hispanic  race_asian  NumPlace  Age_Mom  Age_Dad  ...  \\\n",
       "0              0           0       1.0     47.0     45.0  ...   \n",
       "1              0           0       1.0     41.0     48.0  ...   \n",
       "2              0           0       NaN      NaN      NaN  ...   \n",
       "3              0           0       1.0     43.0     55.0  ...   \n",
       "4              0           0       1.0     38.0     39.0  ...   \n",
       "\n",
       "  BelowHighSchool_Dad BelowHighSchool_Mom  JobScore_Mom  JobScore_Dad  \\\n",
       "0                 0.0                 0.0         53.50          77.5   \n",
       "1                 0.0                 0.0         34.95          53.5   \n",
       "2                 NaN                 NaN           NaN           NaN   \n",
       "3                 0.0                 0.0         63.43          53.5   \n",
       "4                 0.0                 0.0         53.50          53.5   \n",
       "\n",
       "             IncomeCat   Income Poverty  FoodStamp  Score_t  Score_sd  \n",
       "0   $50,001 TO $75,000  62500.5     0.0        0.0   60.043  0.981753  \n",
       "1   $40,001 TO $50,000  45000.5     0.0        0.0   56.280  0.594378  \n",
       "2                  NaN      NaN     NaN        NaN   53.791  0.338152  \n",
       "3   $50,001 TO $75,000  62500.5     0.0        0.0   55.272  0.490611  \n",
       "4  $75,001 TO $100,000  87500.5     0.0        0.0   64.604  1.451278  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_ecls.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESCRIPTIVE STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
       "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
       "│ │ Number of rows    │ 11078  │ │ float64     │ 12    │                                                          │\n",
       "│ │ Number of columns │ 22     │ │ string      │ 5     │                                                          │\n",
       "│ └───────────────────┴────────┘ │ int32       │ 5     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name    </span>┃<span style=\"font-weight: bold\"> NA   </span>┃<span style=\"font-weight: bold\"> NA %  </span>┃<span style=\"font-weight: bold\"> mean       </span>┃<span style=\"font-weight: bold\"> sd     </span>┃<span style=\"font-weight: bold\"> p0     </span>┃<span style=\"font-weight: bold\"> p25     </span>┃<span style=\"font-weight: bold\"> p50    </span>┃<span style=\"font-weight: bold\"> p75    </span>┃<span style=\"font-weight: bold\"> p100   </span>┃<span style=\"font-weight: bold\"> hist   </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">catholic      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1363</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3431</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_white    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.5792</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.4937</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▆    ▇</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_black    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1252</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.331</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_hispanic </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1745</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3795</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_asian    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.06445</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.2456</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">NumPlace      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1575</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">14.22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1.127</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3886</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     6</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇▁  </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Age_Mom       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1615</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">14.58</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     37.85</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  6.44</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     33</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    38</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    42</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    76</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▇▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Age_Dad       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">3232</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">29.17</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     40.64</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 6.882</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     36</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    40</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    45</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    81</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▆▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">BelowHighSchoo</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">3210</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">28.98</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.4527</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.4978</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▇</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">l_Dad         </span> │      │       │            │        │        │         │        │        │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">BelowHighSchoo</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1592</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">14.37</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.4296</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.495</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▆</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">l_Mom         </span> │      │       │            │        │        │         │        │        │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">JobScore_Mom  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">3755</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 33.9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     43.79</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 11.22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  29.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  34.95</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 38.18</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  53.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  77.5</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▆▃▁▃ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">JobScore_Dad  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">3571</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">32.24</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      43.3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 10.84</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  29.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  35.78</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 39.18</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  53.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  77.5</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▅▅▁▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Income        </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1374</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 12.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     58800</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 45150</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  5000</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  27500</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 45000</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 87500</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">200000</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▇▃ ▂▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Poverty       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1374</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 12.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1931</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3948</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">FoodStamp     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">1524</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">13.76</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1129</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3165</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Score_t       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     50.51</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 9.714</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 15.92</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  44.09</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 51.21</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 57.14</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 83.86</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▇▂ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Score_sd      </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-3.348e-16</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-3.561</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6609</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.0723</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.6831</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.434</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▇▂ </span> │  │\n",
       "│ └────────────────┴──────┴───────┴────────────┴────────┴────────┴─────────┴────────┴────────┴────────┴────────┘  │\n",
       "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name              </span>┃<span style=\"font-weight: bold\"> NA         </span>┃<span style=\"font-weight: bold\"> NA %       </span>┃<span style=\"font-weight: bold\"> words per row               </span>┃<span style=\"font-weight: bold\"> total words             </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">childid                 </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                          1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  11078</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race                    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        2.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  30661</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Ed_Dad                  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1374</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      12.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        2.3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  25406</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Ed_Mom                  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1374</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      12.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        2.3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  25537</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">IncomeCat               </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1374</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      12.4</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                        2.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                  29112</span> │  │\n",
       "│ └──────────────────────────┴────────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                          │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
       "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                          │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
       "│ │ Number of rows    │ 11078  │ │ float64     │ 12    │                                                          │\n",
       "│ │ Number of columns │ 22     │ │ string      │ 5     │                                                          │\n",
       "│ └───────────────────┴────────┘ │ int32       │ 5     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA % \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist  \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mcatholic      \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m    0.1363\u001b[0m │ \u001b[36m0.3431\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_white    \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m    0.5792\u001b[0m │ \u001b[36m0.4937\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▆    ▇\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_black    \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m    0.1252\u001b[0m │ \u001b[36m 0.331\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_hispanic \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m    0.1745\u001b[0m │ \u001b[36m0.3795\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_asian    \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m   0.06445\u001b[0m │ \u001b[36m0.2456\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mNumPlace      \u001b[0m │ \u001b[36m1575\u001b[0m │ \u001b[36m14.22\u001b[0m │ \u001b[36m     1.127\u001b[0m │ \u001b[36m0.3886\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m      1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     6\u001b[0m │ \u001b[32m  ▇▁  \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mAge_Mom       \u001b[0m │ \u001b[36m1615\u001b[0m │ \u001b[36m14.58\u001b[0m │ \u001b[36m     37.85\u001b[0m │ \u001b[36m  6.44\u001b[0m │ \u001b[36m    19\u001b[0m │ \u001b[36m     33\u001b[0m │ \u001b[36m    38\u001b[0m │ \u001b[36m    42\u001b[0m │ \u001b[36m    76\u001b[0m │ \u001b[32m ▁▇▇▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mAge_Dad       \u001b[0m │ \u001b[36m3232\u001b[0m │ \u001b[36m29.17\u001b[0m │ \u001b[36m     40.64\u001b[0m │ \u001b[36m 6.882\u001b[0m │ \u001b[36m    22\u001b[0m │ \u001b[36m     36\u001b[0m │ \u001b[36m    40\u001b[0m │ \u001b[36m    45\u001b[0m │ \u001b[36m    81\u001b[0m │ \u001b[32m ▁▇▆▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mBelowHighSchoo\u001b[0m │ \u001b[36m3210\u001b[0m │ \u001b[36m28.98\u001b[0m │ \u001b[36m    0.4527\u001b[0m │ \u001b[36m0.4978\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▇\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141ml_Dad         \u001b[0m │      │       │            │        │        │         │        │        │        │        │  │\n",
       "│ │ \u001b[38;5;141mBelowHighSchoo\u001b[0m │ \u001b[36m1592\u001b[0m │ \u001b[36m14.37\u001b[0m │ \u001b[36m    0.4296\u001b[0m │ \u001b[36m 0.495\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▆\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141ml_Mom         \u001b[0m │      │       │            │        │        │         │        │        │        │        │  │\n",
       "│ │ \u001b[38;5;141mJobScore_Mom  \u001b[0m │ \u001b[36m3755\u001b[0m │ \u001b[36m 33.9\u001b[0m │ \u001b[36m     43.79\u001b[0m │ \u001b[36m 11.22\u001b[0m │ \u001b[36m  29.6\u001b[0m │ \u001b[36m  34.95\u001b[0m │ \u001b[36m 38.18\u001b[0m │ \u001b[36m  53.5\u001b[0m │ \u001b[36m  77.5\u001b[0m │ \u001b[32m▇▆▃▁▃ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mJobScore_Dad  \u001b[0m │ \u001b[36m3571\u001b[0m │ \u001b[36m32.24\u001b[0m │ \u001b[36m      43.3\u001b[0m │ \u001b[36m 10.84\u001b[0m │ \u001b[36m  29.6\u001b[0m │ \u001b[36m  35.78\u001b[0m │ \u001b[36m 39.18\u001b[0m │ \u001b[36m  53.5\u001b[0m │ \u001b[36m  77.5\u001b[0m │ \u001b[32m▇▅▅▁▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mIncome        \u001b[0m │ \u001b[36m1374\u001b[0m │ \u001b[36m 12.4\u001b[0m │ \u001b[36m     58800\u001b[0m │ \u001b[36m 45150\u001b[0m │ \u001b[36m  5000\u001b[0m │ \u001b[36m  27500\u001b[0m │ \u001b[36m 45000\u001b[0m │ \u001b[36m 87500\u001b[0m │ \u001b[36m200000\u001b[0m │ \u001b[32m▇▇▃ ▂▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mPoverty       \u001b[0m │ \u001b[36m1374\u001b[0m │ \u001b[36m 12.4\u001b[0m │ \u001b[36m    0.1931\u001b[0m │ \u001b[36m0.3948\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mFoodStamp     \u001b[0m │ \u001b[36m1524\u001b[0m │ \u001b[36m13.76\u001b[0m │ \u001b[36m    0.1129\u001b[0m │ \u001b[36m0.3165\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mScore_t       \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m     50.51\u001b[0m │ \u001b[36m 9.714\u001b[0m │ \u001b[36m 15.92\u001b[0m │ \u001b[36m  44.09\u001b[0m │ \u001b[36m 51.21\u001b[0m │ \u001b[36m 57.14\u001b[0m │ \u001b[36m 83.86\u001b[0m │ \u001b[32m ▂▇▇▂ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mScore_sd      \u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0\u001b[0m │ \u001b[36m-3.348e-16\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-3.561\u001b[0m │ \u001b[36m-0.6609\u001b[0m │ \u001b[36m0.0723\u001b[0m │ \u001b[36m0.6831\u001b[0m │ \u001b[36m 3.434\u001b[0m │ \u001b[32m ▂▇▇▂ \u001b[0m │  │\n",
       "│ └────────────────┴──────┴───────┴────────────┴────────┴────────┴─────────┴────────┴────────┴────────┴────────┘  │\n",
       "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per row              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal words            \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mchildid                 \u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                          1\u001b[0m │ \u001b[36m                  11078\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace                    \u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                        2.8\u001b[0m │ \u001b[36m                  30661\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mEd_Dad                  \u001b[0m │ \u001b[36m      1374\u001b[0m │ \u001b[36m      12.4\u001b[0m │ \u001b[36m                        2.3\u001b[0m │ \u001b[36m                  25406\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mEd_Mom                  \u001b[0m │ \u001b[36m      1374\u001b[0m │ \u001b[36m      12.4\u001b[0m │ \u001b[36m                        2.3\u001b[0m │ \u001b[36m                  25537\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mIncomeCat               \u001b[0m │ \u001b[36m      1374\u001b[0m │ \u001b[36m      12.4\u001b[0m │ \u001b[36m                        2.6\u001b[0m │ \u001b[36m                  29112\u001b[0m │  │\n",
       "│ └──────────────────────────┴────────────┴────────────┴─────────────────────────────┴─────────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skim(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install qolmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --force-reinstall -U setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qolmat.imputations import imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qolmat.benchmark import comparator, missing_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qolmat.imputations import preprocessing\n",
    "from qolmat.imputations.imputers import ImputerRegressor\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using Qolmat to imput the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"NumPlace\", \"Age_Mom\", \"Age_Dad\", \"BelowHighSchool_Dad\", \"BelowHighSchool_Mom\", \"JobScore_Mom\", \"JobScore_Dad\",\n",
    "           \"Income\", \"Poverty\", \"FoodStamp\"]\n",
    "cat_cols = [\"Ed_Dad\", \"Ed_Mom\", \"IncomeCat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_simple = imputers.ImputerSimple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_rpca = imputers.ImputerRpcaNoisy()\n",
    "ohe = preprocessing.OneHotEncoderProjector(\n",
    "    handle_unknown=\"ignore\",\n",
    "    handle_missing=\"return_nan\",\n",
    "    use_cat_names=True,\n",
    "    cols=cat_cols,\n",
    ")\n",
    "bt = preprocessing.BinTransformer(cols=num_cols)\n",
    "wrapper = Pipeline(steps=[(\"OneHotEncoder\", ohe), (\"BinTransformer\", bt)])\n",
    "imputer_wrap_rpca = preprocessing.WrapperTransformer(imputer_rpca, wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipestimator = preprocessing.make_robust_MixteHGB(avoid_new=True)\n",
    "imputer_hgb = ImputerRegressor(estimator=pipestimator, handler_nan=\"none\")\n",
    "imputer_wrap_hgb = preprocessing.WrapperTransformer(imputer_hgb, bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: Simple..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\qolmat\\benchmark\\missing_patterns.py:203: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_mask[col].iloc[indices] = True\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\qolmat\\benchmark\\missing_patterns.py:203: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_mask[col].iloc[indices] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Testing model: HGB..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\qolmat\\benchmark\\missing_patterns.py:203: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_mask[col].iloc[indices] = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Testing model: RPCA..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dict_imputers = {\n",
    "    \"Simple\": imputer_simple,\n",
    "    \"HGB\": imputer_wrap_hgb,\n",
    "    \"RPCA\": imputer_wrap_rpca,\n",
    "}\n",
    "cols_to_impute = [\"NumPlace\", \"Age_Mom\", \"Age_Dad\", \"BelowHighSchool_Dad\", \"BelowHighSchool_Mom\", \"JobScore_Mom\", \"JobScore_Dad\",\n",
    "           \"Income\", \"Poverty\", \"FoodStamp\", \"Ed_Dad\", \"Ed_Mom\", \"IncomeCat\"]\n",
    "ratio_masked = 0.1\n",
    "generator_holes = missing_patterns.UniformHoleGenerator(\n",
    "    n_splits=2,\n",
    "    subset=cols_to_impute,\n",
    "    ratio_masked=ratio_masked,\n",
    "    sample_proportional=False,\n",
    ")\n",
    "metrics = [\"rmse\", \"accuracy\"]\n",
    "\n",
    "comparison = comparator.Comparator(\n",
    "    dict_imputers,\n",
    "    cols_to_impute,\n",
    "    generator_holes=generator_holes,\n",
    "    metrics=metrics,\n",
    "    max_evals=2,\n",
    ")\n",
    "results = comparison.compare(df[[\"NumPlace\", \"Age_Mom\", \"Age_Dad\", \"BelowHighSchool_Dad\", \"BelowHighSchool_Mom\", \"JobScore_Mom\", \"JobScore_Dad\",\n",
    "           \"Income\", \"Poverty\", \"FoodStamp\", \"Ed_Dad\", \"Ed_Mom\", \"IncomeCat\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Jinja2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_29707_row0_col2, #T_29707_row1_col1, #T_29707_row2_col2, #T_29707_row3_col2, #T_29707_row4_col1, #T_29707_row5_col1, #T_29707_row6_col1, #T_29707_row7_col2, #T_29707_row8_col1, #T_29707_row9_col1 {\n",
       "  background-color: blue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_29707\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_29707_level0_col0\" class=\"col_heading level0 col0\" >Simple</th>\n",
       "      <th id=\"T_29707_level0_col1\" class=\"col_heading level0 col1\" >HGB</th>\n",
       "      <th id=\"T_29707_level0_col2\" class=\"col_heading level0 col2\" >RPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row0\" class=\"row_heading level0 row0\" >NumPlace</th>\n",
       "      <td id=\"T_29707_row0_col0\" class=\"data row0 col0\" >0.401374</td>\n",
       "      <td id=\"T_29707_row0_col1\" class=\"data row0 col1\" >0.389291</td>\n",
       "      <td id=\"T_29707_row0_col2\" class=\"data row0 col2\" >0.373158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row1\" class=\"row_heading level0 row1\" >Age_Mom</th>\n",
       "      <td id=\"T_29707_row1_col0\" class=\"data row1 col0\" >6.424053</td>\n",
       "      <td id=\"T_29707_row1_col1\" class=\"data row1 col1\" >5.105605</td>\n",
       "      <td id=\"T_29707_row1_col2\" class=\"data row1 col2\" >5.151714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row2\" class=\"row_heading level0 row2\" >Age_Dad</th>\n",
       "      <td id=\"T_29707_row2_col0\" class=\"data row2 col0\" >7.090031</td>\n",
       "      <td id=\"T_29707_row2_col1\" class=\"data row2 col1\" >4.993232</td>\n",
       "      <td id=\"T_29707_row2_col2\" class=\"data row2 col2\" >4.883965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row3\" class=\"row_heading level0 row3\" >BelowHighSchool_Dad</th>\n",
       "      <td id=\"T_29707_row3_col0\" class=\"data row3 col0\" >0.676780</td>\n",
       "      <td id=\"T_29707_row3_col1\" class=\"data row3 col1\" >0.175155</td>\n",
       "      <td id=\"T_29707_row3_col2\" class=\"data row3 col2\" >0.172080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row4\" class=\"row_heading level0 row4\" >BelowHighSchool_Mom</th>\n",
       "      <td id=\"T_29707_row4_col0\" class=\"data row4 col0\" >0.662882</td>\n",
       "      <td id=\"T_29707_row4_col1\" class=\"data row4 col1\" >0.180096</td>\n",
       "      <td id=\"T_29707_row4_col2\" class=\"data row4 col2\" >0.180253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row5\" class=\"row_heading level0 row5\" >JobScore_Mom</th>\n",
       "      <td id=\"T_29707_row5_col0\" class=\"data row5 col0\" >12.456851</td>\n",
       "      <td id=\"T_29707_row5_col1\" class=\"data row5 col1\" >9.559773</td>\n",
       "      <td id=\"T_29707_row5_col2\" class=\"data row5 col2\" >9.802122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row6\" class=\"row_heading level0 row6\" >JobScore_Dad</th>\n",
       "      <td id=\"T_29707_row6_col0\" class=\"data row6 col0\" >11.384039</td>\n",
       "      <td id=\"T_29707_row6_col1\" class=\"data row6 col1\" >8.575160</td>\n",
       "      <td id=\"T_29707_row6_col2\" class=\"data row6 col2\" >8.846237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row7\" class=\"row_heading level0 row7\" >Income</th>\n",
       "      <td id=\"T_29707_row7_col0\" class=\"data row7 col0\" >46471.940318</td>\n",
       "      <td id=\"T_29707_row7_col1\" class=\"data row7 col1\" >12203.876845</td>\n",
       "      <td id=\"T_29707_row7_col2\" class=\"data row7 col2\" >11715.905537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row8\" class=\"row_heading level0 row8\" >Poverty</th>\n",
       "      <td id=\"T_29707_row8_col0\" class=\"data row8 col0\" >0.438431</td>\n",
       "      <td id=\"T_29707_row8_col1\" class=\"data row8 col1\" >0.212387</td>\n",
       "      <td id=\"T_29707_row8_col2\" class=\"data row8 col2\" >0.241948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29707_level0_row9\" class=\"row_heading level0 row9\" >FoodStamp</th>\n",
       "      <td id=\"T_29707_row9_col0\" class=\"data row9 col0\" >0.343845</td>\n",
       "      <td id=\"T_29707_row9_col1\" class=\"data row9 col1\" >0.304862</td>\n",
       "      <td id=\"T_29707_row9_col2\" class=\"data row9 col2\" >0.310010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x215705ae7b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[\"rmse\"].style.highlight_min(color=\"blue\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9611b_row0_col0, #T_9611b_row1_col2, #T_9611b_row2_col2, #T_9611b_row3_col2, #T_9611b_row4_col1, #T_9611b_row4_col2, #T_9611b_row5_col0, #T_9611b_row6_col1, #T_9611b_row7_col2, #T_9611b_row8_col1, #T_9611b_row9_col1, #T_9611b_row10_col1, #T_9611b_row11_col1, #T_9611b_row12_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9611b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9611b_level0_col0\" class=\"col_heading level0 col0\" >Simple</th>\n",
       "      <th id=\"T_9611b_level0_col1\" class=\"col_heading level0 col1\" >HGB</th>\n",
       "      <th id=\"T_9611b_level0_col2\" class=\"col_heading level0 col2\" >RPCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row0\" class=\"row_heading level0 row0\" >NumPlace</th>\n",
       "      <td id=\"T_9611b_row0_col0\" class=\"data row0 col0\" >0.898466</td>\n",
       "      <td id=\"T_9611b_row0_col1\" class=\"data row0 col1\" >0.879964</td>\n",
       "      <td id=\"T_9611b_row0_col2\" class=\"data row0 col2\" >0.891245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row1\" class=\"row_heading level0 row1\" >Age_Mom</th>\n",
       "      <td id=\"T_9611b_row1_col0\" class=\"data row1 col0\" >0.057310</td>\n",
       "      <td id=\"T_9611b_row1_col1\" class=\"data row1 col1\" >0.097924</td>\n",
       "      <td id=\"T_9611b_row1_col2\" class=\"data row1 col2\" >0.099278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row2\" class=\"row_heading level0 row2\" >Age_Dad</th>\n",
       "      <td id=\"T_9611b_row2_col0\" class=\"data row2 col0\" >0.067238</td>\n",
       "      <td id=\"T_9611b_row2_col1\" class=\"data row2 col1\" >0.088448</td>\n",
       "      <td id=\"T_9611b_row2_col2\" class=\"data row2 col2\" >0.102437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row3\" class=\"row_heading level0 row3\" >BelowHighSchool_Dad</th>\n",
       "      <td id=\"T_9611b_row3_col0\" class=\"data row3 col0\" >0.541968</td>\n",
       "      <td id=\"T_9611b_row3_col1\" class=\"data row3 col1\" >0.969314</td>\n",
       "      <td id=\"T_9611b_row3_col2\" class=\"data row3 col2\" >0.970217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row4\" class=\"row_heading level0 row4\" >BelowHighSchool_Mom</th>\n",
       "      <td id=\"T_9611b_row4_col0\" class=\"data row4 col0\" >0.560469</td>\n",
       "      <td id=\"T_9611b_row4_col1\" class=\"data row4 col1\" >0.967509</td>\n",
       "      <td id=\"T_9611b_row4_col2\" class=\"data row4 col2\" >0.967509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row5\" class=\"row_heading level0 row5\" >JobScore_Mom</th>\n",
       "      <td id=\"T_9611b_row5_col0\" class=\"data row5 col0\" >0.275722</td>\n",
       "      <td id=\"T_9611b_row5_col1\" class=\"data row5 col1\" >0.043321</td>\n",
       "      <td id=\"T_9611b_row5_col2\" class=\"data row5 col2\" >0.036101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row6\" class=\"row_heading level0 row6\" >JobScore_Dad</th>\n",
       "      <td id=\"T_9611b_row6_col0\" class=\"data row6 col0\" >0.080325</td>\n",
       "      <td id=\"T_9611b_row6_col1\" class=\"data row6 col1\" >0.092509</td>\n",
       "      <td id=\"T_9611b_row6_col2\" class=\"data row6 col2\" >0.091155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row7\" class=\"row_heading level0 row7\" >Income</th>\n",
       "      <td id=\"T_9611b_row7_col0\" class=\"data row7 col0\" >0.124097</td>\n",
       "      <td id=\"T_9611b_row7_col1\" class=\"data row7 col1\" >0.903881</td>\n",
       "      <td id=\"T_9611b_row7_col2\" class=\"data row7 col2\" >0.923285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row8\" class=\"row_heading level0 row8\" >Poverty</th>\n",
       "      <td id=\"T_9611b_row8_col0\" class=\"data row8 col0\" >0.807762</td>\n",
       "      <td id=\"T_9611b_row8_col1\" class=\"data row8 col1\" >0.954874</td>\n",
       "      <td id=\"T_9611b_row8_col2\" class=\"data row8 col2\" >0.941336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row9\" class=\"row_heading level0 row9\" >FoodStamp</th>\n",
       "      <td id=\"T_9611b_row9_col0\" class=\"data row9 col0\" >0.881769</td>\n",
       "      <td id=\"T_9611b_row9_col1\" class=\"data row9 col1\" >0.907040</td>\n",
       "      <td id=\"T_9611b_row9_col2\" class=\"data row9 col2\" >0.903881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row10\" class=\"row_heading level0 row10\" >Ed_Dad</th>\n",
       "      <td id=\"T_9611b_row10_col0\" class=\"data row10 col0\" >0.219765</td>\n",
       "      <td id=\"T_9611b_row10_col1\" class=\"data row10 col1\" >0.621390</td>\n",
       "      <td id=\"T_9611b_row10_col2\" class=\"data row10 col2\" >0.534296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row11\" class=\"row_heading level0 row11\" >Ed_Mom</th>\n",
       "      <td id=\"T_9611b_row11_col0\" class=\"data row11 col0\" >0.300993</td>\n",
       "      <td id=\"T_9611b_row11_col1\" class=\"data row11 col1\" >0.577166</td>\n",
       "      <td id=\"T_9611b_row11_col2\" class=\"data row11 col2\" >0.559116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9611b_level0_row12\" class=\"row_heading level0 row12\" >IncomeCat</th>\n",
       "      <td id=\"T_9611b_row12_col0\" class=\"data row12 col0\" >0.194495</td>\n",
       "      <td id=\"T_9611b_row12_col1\" class=\"data row12 col1\" >0.918773</td>\n",
       "      <td id=\"T_9611b_row12_col2\" class=\"data row12 col2\" >0.338448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21570776d80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[\"accuracy\"].style.highlight_max(color=\"green\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_impute = [\"NumPlace\", \"Age_Mom\", \"Age_Dad\", \"BelowHighSchool_Dad\", \"BelowHighSchool_Mom\", \"JobScore_Mom\", \"JobScore_Dad\",\n",
    "           \"Income\", \"Poverty\", \"FoodStamp\", \"Ed_Dad\", \"Ed_Mom\", \"IncomeCat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_1 = {name: imp for name, imp in dict_imputers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = dic_1[\"HGB\"].fit_transform(df_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.to_csv('data_ecls_imputed.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ <span style=\"font-style: italic\">         Data Summary         </span> <span style=\"font-style: italic\">      Data Types       </span>                                                          │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
       "│ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> dataframe         </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Values </span>┃ ┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Column Type </span>┃<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> Count </span>┃                                                          │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
       "│ │ Number of rows    │ 11078  │ │ float64     │ 12    │                                                          │\n",
       "│ │ Number of columns │ 22     │ │ string      │ 5     │                                                          │\n",
       "│ └───────────────────┴────────┘ │ int32       │ 5     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ <span style=\"font-style: italic\">                                                    number                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name       </span>┃<span style=\"font-weight: bold\"> NA </span>┃<span style=\"font-weight: bold\"> NA % </span>┃<span style=\"font-weight: bold\"> mean       </span>┃<span style=\"font-weight: bold\"> sd     </span>┃<span style=\"font-weight: bold\"> p0     </span>┃<span style=\"font-weight: bold\"> p25     </span>┃<span style=\"font-weight: bold\"> p50    </span>┃<span style=\"font-weight: bold\"> p75    </span>┃<span style=\"font-weight: bold\"> p100   </span>┃<span style=\"font-weight: bold\"> hist   </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">catholic         </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1363</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3431</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_white       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.5792</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.4937</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▆    ▇</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_black       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1252</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.331</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_hispanic    </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1745</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3795</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race_asian       </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.06445</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.2456</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">NumPlace         </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1.109</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3627</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     6</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">  ▇▁  </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Age_Mom          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     37.84</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 6.031</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    19</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     34</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    38</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    41</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    76</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▇▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Age_Dad          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     40.82</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 6.554</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    22</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     37</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    40</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    44</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    81</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▁▇▅▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">BelowHighSchool_D</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.3215</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.4671</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▃</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">ad               </span> │    │      │            │        │        │         │        │        │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">BelowHighSchool_M</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.3678</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.4822</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▅</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">om               </span> │    │      │            │        │        │         │        │        │        │        │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">JobScore_Mom     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      44.9</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 10.62</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  29.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  35.78</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 38.18</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  53.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  77.5</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▇▅▃▃ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">JobScore_Dad     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     44.32</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 9.854</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  29.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  35.92</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  39.2</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  53.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  77.5</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▇▇▁▁ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Income           </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     54300</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 43920</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  5000</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  22500</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 37500</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 62500</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">200000</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇▆▂ ▂ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Poverty          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">    0.1692</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.3749</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▂</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">FoodStamp        </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0.09921</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0.299</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008000; text-decoration-color: #008000\">▇    ▁</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Score_t          </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     50.51</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 9.714</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 15.92</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">  44.09</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 51.21</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 57.14</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 83.86</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▇▂ </span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Score_sd         </span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">   0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-3.348e-16</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">     1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-3.561</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">-0.6609</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.0723</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">0.6831</span> │ <span style=\"color: #008080; text-decoration-color: #008080\"> 3.434</span> │ <span style=\"color: #008000; text-decoration-color: #008000\"> ▂▇▇▂ </span> │  │\n",
       "│ └───────────────────┴────┴──────┴────────────┴────────┴────────┴─────────┴────────┴────────┴────────┴────────┘  │\n",
       "│ <span style=\"font-style: italic\">                                                    string                                                    </span>  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃<span style=\"font-weight: bold\"> column_name               </span>┃<span style=\"font-weight: bold\"> NA      </span>┃<span style=\"font-weight: bold\"> NA %       </span>┃<span style=\"font-weight: bold\"> words per row                </span>┃<span style=\"font-weight: bold\"> total words              </span>┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">childid                  </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                           1</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                   11078</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">race                     </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                         2.8</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                   30661</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Ed_Dad                   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                         2.5</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                   28154</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">Ed_Mom                   </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                         2.6</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                   28285</span> │  │\n",
       "│ │ <span style=\"color: #af87ff; text-decoration-color: #af87ff\">IncomeCat                </span> │ <span style=\"color: #008080; text-decoration-color: #008080\">      0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">         0</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                           3</span> │ <span style=\"color: #008080; text-decoration-color: #008080\">                   33234</span> │  │\n",
       "│ └───────────────────────────┴─────────┴────────────┴──────────────────────────────┴──────────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────────────────────────────────────── skimpy summary ─────────────────────────────────────────────────╮\n",
       "│ \u001b[3m         Data Summary         \u001b[0m \u001b[3m      Data Types       \u001b[0m                                                          │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓ ┏━━━━━━━━━━━━━┳━━━━━━━┓                                                          │\n",
       "│ ┃\u001b[1;36m \u001b[0m\u001b[1;36mdataframe        \u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mValues\u001b[0m\u001b[1;36m \u001b[0m┃ ┃\u001b[1;36m \u001b[0m\u001b[1;36mColumn Type\u001b[0m\u001b[1;36m \u001b[0m┃\u001b[1;36m \u001b[0m\u001b[1;36mCount\u001b[0m\u001b[1;36m \u001b[0m┃                                                          │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩ ┡━━━━━━━━━━━━━╇━━━━━━━┩                                                          │\n",
       "│ │ Number of rows    │ 11078  │ │ float64     │ 12    │                                                          │\n",
       "│ │ Number of columns │ 22     │ │ string      │ 5     │                                                          │\n",
       "│ └───────────────────┴────────┘ │ int32       │ 5     │                                                          │\n",
       "│                                └─────────────┴───────┘                                                          │\n",
       "│ \u001b[3m                                                    number                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━┳━━━━┳━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmean      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msd    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp0    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp25    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp50   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp75   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mp100  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mhist  \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━╇━━━━╇━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mcatholic         \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.1363\u001b[0m │ \u001b[36m0.3431\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_white       \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.5792\u001b[0m │ \u001b[36m0.4937\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▆    ▇\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_black       \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.1252\u001b[0m │ \u001b[36m 0.331\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_hispanic    \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.1745\u001b[0m │ \u001b[36m0.3795\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace_asian       \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.06445\u001b[0m │ \u001b[36m0.2456\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mNumPlace         \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     1.109\u001b[0m │ \u001b[36m0.3627\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m      1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     6\u001b[0m │ \u001b[32m  ▇▁  \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mAge_Mom          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     37.84\u001b[0m │ \u001b[36m 6.031\u001b[0m │ \u001b[36m    19\u001b[0m │ \u001b[36m     34\u001b[0m │ \u001b[36m    38\u001b[0m │ \u001b[36m    41\u001b[0m │ \u001b[36m    76\u001b[0m │ \u001b[32m ▁▇▇▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mAge_Dad          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     40.82\u001b[0m │ \u001b[36m 6.554\u001b[0m │ \u001b[36m    22\u001b[0m │ \u001b[36m     37\u001b[0m │ \u001b[36m    40\u001b[0m │ \u001b[36m    44\u001b[0m │ \u001b[36m    81\u001b[0m │ \u001b[32m ▁▇▅▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mBelowHighSchool_D\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.3215\u001b[0m │ \u001b[36m0.4671\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▃\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mad               \u001b[0m │    │      │            │        │        │         │        │        │        │        │  │\n",
       "│ │ \u001b[38;5;141mBelowHighSchool_M\u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.3678\u001b[0m │ \u001b[36m0.4822\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▅\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mom               \u001b[0m │    │      │            │        │        │         │        │        │        │        │  │\n",
       "│ │ \u001b[38;5;141mJobScore_Mom     \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m      44.9\u001b[0m │ \u001b[36m 10.62\u001b[0m │ \u001b[36m  29.6\u001b[0m │ \u001b[36m  35.78\u001b[0m │ \u001b[36m 38.18\u001b[0m │ \u001b[36m  53.5\u001b[0m │ \u001b[36m  77.5\u001b[0m │ \u001b[32m▇▇▅▃▃ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mJobScore_Dad     \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     44.32\u001b[0m │ \u001b[36m 9.854\u001b[0m │ \u001b[36m  29.6\u001b[0m │ \u001b[36m  35.92\u001b[0m │ \u001b[36m  39.2\u001b[0m │ \u001b[36m  53.5\u001b[0m │ \u001b[36m  77.5\u001b[0m │ \u001b[32m▇▇▇▁▁ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mIncome           \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     54300\u001b[0m │ \u001b[36m 43920\u001b[0m │ \u001b[36m  5000\u001b[0m │ \u001b[36m  22500\u001b[0m │ \u001b[36m 37500\u001b[0m │ \u001b[36m 62500\u001b[0m │ \u001b[36m200000\u001b[0m │ \u001b[32m▇▆▂ ▂ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mPoverty          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m    0.1692\u001b[0m │ \u001b[36m0.3749\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▂\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mFoodStamp        \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m   0.09921\u001b[0m │ \u001b[36m 0.299\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     0\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[32m▇    ▁\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mScore_t          \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m     50.51\u001b[0m │ \u001b[36m 9.714\u001b[0m │ \u001b[36m 15.92\u001b[0m │ \u001b[36m  44.09\u001b[0m │ \u001b[36m 51.21\u001b[0m │ \u001b[36m 57.14\u001b[0m │ \u001b[36m 83.86\u001b[0m │ \u001b[32m ▂▇▇▂ \u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mScore_sd         \u001b[0m │ \u001b[36m 0\u001b[0m │ \u001b[36m   0\u001b[0m │ \u001b[36m-3.348e-16\u001b[0m │ \u001b[36m     1\u001b[0m │ \u001b[36m-3.561\u001b[0m │ \u001b[36m-0.6609\u001b[0m │ \u001b[36m0.0723\u001b[0m │ \u001b[36m0.6831\u001b[0m │ \u001b[36m 3.434\u001b[0m │ \u001b[32m ▂▇▇▂ \u001b[0m │  │\n",
       "│ └───────────────────┴────┴──────┴────────────┴────────┴────────┴─────────┴────────┴────────┴────────┴────────┘  │\n",
       "│ \u001b[3m                                                    string                                                    \u001b[0m  │\n",
       "│ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓  │\n",
       "│ ┃\u001b[1m \u001b[0m\u001b[1mcolumn_name              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mNA %      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mwords per row               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mtotal words             \u001b[0m\u001b[1m \u001b[0m┃  │\n",
       "│ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩  │\n",
       "│ │ \u001b[38;5;141mchildid                  \u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                           1\u001b[0m │ \u001b[36m                   11078\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mrace                     \u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                         2.8\u001b[0m │ \u001b[36m                   30661\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mEd_Dad                   \u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                         2.5\u001b[0m │ \u001b[36m                   28154\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mEd_Mom                   \u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                         2.6\u001b[0m │ \u001b[36m                   28285\u001b[0m │  │\n",
       "│ │ \u001b[38;5;141mIncomeCat                \u001b[0m │ \u001b[36m      0\u001b[0m │ \u001b[36m         0\u001b[0m │ \u001b[36m                           3\u001b[0m │ \u001b[36m                   33234\u001b[0m │  │\n",
       "│ └───────────────────────────┴─────────┴────────────┴──────────────────────────────┴──────────────────────────┘  │\n",
       "╰────────────────────────────────────────────────────── End ──────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skim(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     66.10\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):           4.75e-16\n",
      "Time:                        14:58:40   Log-Likelihood:                -40872.\n",
      "No. Observations:               11078   AIC:                         8.175e+04\n",
      "Df Residuals:                   11076   BIC:                         8.176e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     50.2090      0.099    507.064      0.000      50.015      50.403\n",
      "catholic       2.1805      0.268      8.130      0.000       1.655       2.706\n",
      "==============================================================================\n",
      "Omnibus:                       62.455   Durbin-Watson:                   1.635\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.594\n",
      "Skew:                          -0.175   Prob(JB):                     2.56e-14\n",
      "Kurtosis:                       2.884   Cond. No.                         2.98\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_1 = smf.ols(\"Score_t ~ catholic\", data=df).fit()\n",
    "print(mod_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.006\n",
      "Method:                 Least Squares   F-statistic:                     66.10\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):           4.75e-16\n",
      "Time:                        14:58:42   Log-Likelihood:                -40872.\n",
      "No. Observations:               11078   AIC:                         8.175e+04\n",
      "Df Residuals:                   11076   BIC:                         8.176e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     50.2090      0.099    507.064      0.000      50.015      50.403\n",
      "catholic       2.1805      0.268      8.130      0.000       1.655       2.706\n",
      "==============================================================================\n",
      "Omnibus:                       62.455   Durbin-Watson:                   1.635\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               62.594\n",
      "Skew:                          -0.175   Prob(JB):                     2.56e-14\n",
      "Kurtosis:                       2.884   Cond. No.                         2.98\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_2 = smf.ols(\"Score_t ~ catholic\", data=df_imputed).fit()\n",
    "print(mod_2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                  0.106\n",
      "Method:                 Least Squares   F-statistic:                     263.6\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):          3.91e-267\n",
      "Time:                        15:07:18   Log-Likelihood:                -40282.\n",
      "No. Observations:               11078   AIC:                         8.058e+04\n",
      "Df Residuals:                   11072   BIC:                         8.062e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        47.2484      0.367    128.653      0.000      46.528      47.968\n",
      "catholic          1.1182      0.256      4.363      0.000       0.616       1.621\n",
      "race_white        5.3944      0.385     14.027      0.000       4.641       6.148\n",
      "race_black       -2.6274      0.442     -5.946      0.000      -3.493      -1.761\n",
      "race_hispanic    -0.0266      0.422     -0.063      0.950      -0.854       0.800\n",
      "race_asian        4.8830      0.503      9.717      0.000       3.898       5.868\n",
      "==============================================================================\n",
      "Omnibus:                       74.498   Durbin-Watson:                   1.770\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.932\n",
      "Skew:                          -0.198   Prob(JB):                     3.25e-17\n",
      "Kurtosis:                       3.088   Cond. No.                         11.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_3 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian\", data=df).fit()\n",
    "print(mod_3.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                  0.106\n",
      "Method:                 Least Squares   F-statistic:                     263.6\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):          3.91e-267\n",
      "Time:                        15:07:20   Log-Likelihood:                -40282.\n",
      "No. Observations:               11078   AIC:                         8.058e+04\n",
      "Df Residuals:                   11072   BIC:                         8.062e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        47.2484      0.367    128.653      0.000      46.528      47.968\n",
      "catholic          1.1182      0.256      4.363      0.000       0.616       1.621\n",
      "race_white        5.3944      0.385     14.027      0.000       4.641       6.148\n",
      "race_black       -2.6274      0.442     -5.946      0.000      -3.493      -1.761\n",
      "race_hispanic    -0.0266      0.422     -0.063      0.950      -0.854       0.800\n",
      "race_asian        4.8830      0.503      9.717      0.000       3.898       5.868\n",
      "==============================================================================\n",
      "Omnibus:                       74.498   Durbin-Watson:                   1.770\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.932\n",
      "Skew:                          -0.198   Prob(JB):                     3.25e-17\n",
      "Kurtosis:                       3.088   Cond. No.                         11.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_4 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian\", data=df_imputed).fit()\n",
    "print(mod_4.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.105\n",
      "Model:                            OLS   Adj. R-squared:                  0.105\n",
      "Method:                 Least Squares   F-statistic:                     186.2\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):          4.86e-225\n",
      "Time:                        15:08:36   Log-Likelihood:                -34499.\n",
      "No. Observations:                9503   AIC:                         6.901e+04\n",
      "Df Residuals:                    9496   BIC:                         6.906e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        49.0908      0.486    100.948      0.000      48.138      50.044\n",
      "catholic          0.7763      0.269      2.891      0.004       0.250       1.303\n",
      "race_white        5.5579      0.413     13.444      0.000       4.748       6.368\n",
      "race_black       -2.4488      0.486     -5.036      0.000      -3.402      -1.496\n",
      "race_hispanic     0.1703      0.457      0.373      0.709      -0.726       1.066\n",
      "race_asian        5.2796      0.562      9.398      0.000       4.178       6.381\n",
      "NumPlace         -1.4461      0.241     -5.993      0.000      -1.919      -0.973\n",
      "==============================================================================\n",
      "Omnibus:                       76.356   Durbin-Watson:                   1.788\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.301\n",
      "Skew:                          -0.214   Prob(JB):                     9.93e-18\n",
      "Kurtosis:                       3.122   Cond. No.                         16.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_5 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace\", data=df).fit()\n",
    "print(mod_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.108\n",
      "Model:                            OLS   Adj. R-squared:                  0.108\n",
      "Method:                 Least Squares   F-statistic:                     223.9\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):          8.22e-271\n",
      "Time:                        15:08:45   Log-Likelihood:                -40271.\n",
      "No. Observations:               11078   AIC:                         8.056e+04\n",
      "Df Residuals:                   11071   BIC:                         8.061e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        48.5580      0.458    105.920      0.000      47.659      49.457\n",
      "catholic          1.0839      0.256      4.231      0.000       0.582       1.586\n",
      "race_white        5.3622      0.384     13.954      0.000       4.609       6.115\n",
      "race_black       -2.6800      0.442     -6.070      0.000      -3.546      -1.815\n",
      "race_hispanic    -0.0623      0.422     -0.148      0.883      -0.889       0.764\n",
      "race_asian        4.8419      0.502      9.643      0.000       3.858       5.826\n",
      "NumPlace         -1.1460      0.241     -4.765      0.000      -1.617      -0.675\n",
      "==============================================================================\n",
      "Omnibus:                       71.958   Durbin-Watson:                   1.771\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               73.268\n",
      "Skew:                          -0.195   Prob(JB):                     1.23e-16\n",
      "Kurtosis:                       3.082   Cond. No.                         16.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod_6 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace\", data=df_imputed).fit()\n",
    "print(mod_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.171\n",
      "Model:                            OLS   Adj. R-squared:                  0.170\n",
      "Method:                 Least Squares   F-statistic:                     279.7\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        15:09:56   Log-Likelihood:                -34137.\n",
      "No. Observations:                9503   AIC:                         6.829e+04\n",
      "Df Residuals:                    9495   BIC:                         6.835e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        45.9339      0.482     95.281      0.000      44.989      46.879\n",
      "catholic         -0.5668      0.263     -2.154      0.031      -1.083      -0.051\n",
      "race_white        4.2980      0.401     10.728      0.000       3.513       5.083\n",
      "race_black       -1.6331      0.469     -3.482      0.001      -2.553      -0.714\n",
      "race_hispanic     0.6222      0.440      1.413      0.158      -0.241       1.485\n",
      "race_asian        4.5424      0.541      8.389      0.000       3.481       5.604\n",
      "NumPlace         -0.9955      0.233     -4.275      0.000      -1.452      -0.539\n",
      "Income         5.906e-05   2.15e-06     27.422      0.000    5.48e-05    6.33e-05\n",
      "==============================================================================\n",
      "Omnibus:                       70.719   Durbin-Watson:                   1.880\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               72.188\n",
      "Skew:                          -0.209   Prob(JB):                     2.11e-16\n",
      "Kurtosis:                       3.089   Cond. No.                     7.41e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.41e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod_7 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace + Income\", data=df).fit()\n",
    "print(mod_7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.172\n",
      "Method:                 Least Squares   F-statistic:                     328.7\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        15:09:37   Log-Likelihood:                -39859.\n",
      "No. Observations:               11078   AIC:                         7.973e+04\n",
      "Df Residuals:                   11070   BIC:                         7.979e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        45.7464      0.452    101.185      0.000      44.860      46.633\n",
      "catholic         -0.2417      0.251     -0.963      0.335      -0.734       0.250\n",
      "race_white        4.0959      0.373     10.987      0.000       3.365       4.827\n",
      "race_black       -1.9043      0.426     -4.467      0.000      -2.740      -1.069\n",
      "race_hispanic     0.3651      0.406      0.898      0.369      -0.432       1.162\n",
      "race_asian        4.4707      0.484      9.238      0.000       3.522       5.419\n",
      "NumPlace         -0.8769      0.232     -3.781      0.000      -1.332      -0.422\n",
      "Income          6.04e-05   2.07e-06     29.217      0.000    5.63e-05    6.45e-05\n",
      "==============================================================================\n",
      "Omnibus:                       68.465   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.589\n",
      "Skew:                          -0.192   Prob(JB):                     7.74e-16\n",
      "Kurtosis:                       3.059   Cond. No.                     6.90e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.9e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod_8 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace + Income\", data=df_imputed).fit()\n",
    "print(mod_8.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.154\n",
      "Model:                            OLS   Adj. R-squared:                  0.153\n",
      "Method:                 Least Squares   F-statistic:                     110.3\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):          1.08e-190\n",
      "Time:                        15:11:03   Log-Likelihood:                -19484.\n",
      "No. Observations:                5467   AIC:                         3.899e+04\n",
      "Df Residuals:                    5457   BIC:                         3.905e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        40.0474      0.866     46.237      0.000      38.349      41.745\n",
      "catholic         -1.2380      0.313     -3.949      0.000      -1.852      -0.623\n",
      "race_white        4.1549      0.530      7.840      0.000       3.116       5.194\n",
      "race_black       -1.0297      0.679     -1.517      0.129      -2.360       0.301\n",
      "race_hispanic     0.9146      0.591      1.546      0.122      -0.245       2.074\n",
      "race_asian        4.6285      0.685      6.755      0.000       3.285       5.972\n",
      "NumPlace         -0.8546      0.340     -2.515      0.012      -1.521      -0.188\n",
      "Income         3.969e-05   3.11e-06     12.760      0.000    3.36e-05    4.58e-05\n",
      "JobScore_Mom      0.0897      0.011      8.108      0.000       0.068       0.111\n",
      "JobScore_Dad      0.0788      0.012      6.513      0.000       0.055       0.103\n",
      "==============================================================================\n",
      "Omnibus:                       43.135   Durbin-Watson:                   1.898\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               44.104\n",
      "Skew:                          -0.211   Prob(JB):                     2.65e-10\n",
      "Kurtosis:                       3.125   Cond. No.                     8.70e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.7e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod_9 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace + Income + JobScore_Mom + JobScore_Dad\", data=df).fit()\n",
    "print(mod_9.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Score_t   R-squared:                       0.181\n",
      "Model:                            OLS   Adj. R-squared:                  0.181\n",
      "Method:                 Least Squares   F-statistic:                     272.3\n",
      "Date:                Wed, 20 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        15:11:22   Log-Likelihood:                -39797.\n",
      "No. Observations:               11078   AIC:                         7.961e+04\n",
      "Df Residuals:                   11068   BIC:                         7.969e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        41.1636      0.635     64.788      0.000      39.918      42.409\n",
      "catholic         -0.4316      0.250     -1.725      0.085      -0.922       0.059\n",
      "race_white        4.0573      0.371     10.943      0.000       3.331       4.784\n",
      "race_black       -1.9859      0.424     -4.683      0.000      -2.817      -1.155\n",
      "race_hispanic     0.5314      0.405      1.314      0.189      -0.262       1.324\n",
      "race_asian        4.3175      0.482      8.964      0.000       3.373       5.262\n",
      "NumPlace         -0.6424      0.232     -2.773      0.006      -1.097      -0.188\n",
      "Income         5.481e-05   2.14e-06     25.580      0.000    5.06e-05     5.9e-05\n",
      "JobScore_Mom      0.0812      0.009      9.174      0.000       0.064       0.099\n",
      "JobScore_Dad      0.0230      0.010      2.379      0.017       0.004       0.042\n",
      "==============================================================================\n",
      "Omnibus:                       67.321   Durbin-Watson:                   1.868\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               68.404\n",
      "Skew:                          -0.190   Prob(JB):                     1.40e-15\n",
      "Kurtosis:                       3.059   Cond. No.                     7.17e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.17e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "mod_10 = smf.ols(\"Score_t ~ catholic + race_white+ race_black + race_hispanic + race_asian  + NumPlace + Income + JobScore_Mom + JobScore_Dad\", data=df_imputed).fit()\n",
    "print(mod_10.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"5\"><em>Dependent variable: Score_t</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Income</td><td></td><td></td><td></td><td>0.000<sup>***</sup></td><td>0.000<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.000)</td><td>(0.000)</td></tr>\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>50.209<sup>***</sup></td><td>47.248<sup>***</sup></td><td>49.091<sup>***</sup></td><td>45.934<sup>***</sup></td><td>40.047<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.099)</td><td>(0.367)</td><td>(0.486)</td><td>(0.482)</td><td>(0.866)</td></tr>\n",
       "<tr><td style=\"text-align:left\">JobScore_Dad</td><td></td><td></td><td></td><td></td><td>0.079<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td>(0.012)</td></tr>\n",
       "<tr><td style=\"text-align:left\">JobScore_Mom</td><td></td><td></td><td></td><td></td><td>0.090<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td>(0.011)</td></tr>\n",
       "<tr><td style=\"text-align:left\">NumPlace</td><td></td><td></td><td>-1.446<sup>***</sup></td><td>-0.996<sup>***</sup></td><td>-0.855<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.241)</td><td>(0.233)</td><td>(0.340)</td></tr>\n",
       "<tr><td style=\"text-align:left\">catholic</td><td>2.180<sup>***</sup></td><td>1.118<sup>***</sup></td><td>0.776<sup>***</sup></td><td>-0.567<sup>**</sup></td><td>-1.238<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td>(0.256)</td><td>(0.269)</td><td>(0.263)</td><td>(0.313)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_asian</td><td></td><td>4.883<sup>***</sup></td><td>5.280<sup>***</sup></td><td>4.542<sup>***</sup></td><td>4.628<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.503)</td><td>(0.562)</td><td>(0.541)</td><td>(0.685)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_black</td><td></td><td>-2.627<sup>***</sup></td><td>-2.449<sup>***</sup></td><td>-1.633<sup>***</sup></td><td>-1.030<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.442)</td><td>(0.486)</td><td>(0.469)</td><td>(0.679)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_hispanic</td><td></td><td>-0.027<sup></sup></td><td>0.170<sup></sup></td><td>0.622<sup></sup></td><td>0.915<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.422)</td><td>(0.457)</td><td>(0.440)</td><td>(0.591)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_white</td><td></td><td>5.394<sup>***</sup></td><td>5.558<sup>***</sup></td><td>4.298<sup>***</sup></td><td>4.155<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.385)</td><td>(0.413)</td><td>(0.401)</td><td>(0.530)</td></tr>\n",
       "\n",
       "<td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>11078</td><td>11078</td><td>9503</td><td>9503</td><td>5467</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.006</td><td>0.106</td><td>0.105</td><td>0.171</td><td>0.154</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.006</td><td>0.106</td><td>0.105</td><td>0.170</td><td>0.153</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>9.686 (df=11076)</td><td>9.185 (df=11072)</td><td>9.131 (df=9496)</td><td>8.791 (df=9495)</td><td>8.550 (df=5457)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>66.096<sup>***</sup> (df=1; 11076)</td><td>263.634<sup>***</sup> (df=5; 11072)</td><td>186.249<sup>***</sup> (df=6; 9496)</td><td>279.691<sup>***</sup> (df=7; 9495)</td><td>110.323<sup>***</sup> (df=9; 5457)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"5\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x21503282750>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gazer_raw = [mod_1, mod_3, mod_5, mod_7, mod_9]\n",
    "gazer_imputed = [mod_2, mod_4, mod_6, mod_8, mod_10]\n",
    "\n",
    "Stargazer(gazer_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the raw data, Going to a catholic school has a significant impact on the math score of students but the impact if nnot consistent(positive and negative) when we control for more variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"5\"><em>Dependent variable: Score_t</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Income</td><td></td><td></td><td></td><td>0.000<sup>***</sup></td><td>0.000<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.000)</td><td>(0.000)</td></tr>\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>50.209<sup>***</sup></td><td>47.248<sup>***</sup></td><td>48.558<sup>***</sup></td><td>45.746<sup>***</sup></td><td>41.164<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.099)</td><td>(0.367)</td><td>(0.458)</td><td>(0.452)</td><td>(0.635)</td></tr>\n",
       "<tr><td style=\"text-align:left\">JobScore_Dad</td><td></td><td></td><td></td><td></td><td>0.023<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td>(0.010)</td></tr>\n",
       "<tr><td style=\"text-align:left\">JobScore_Mom</td><td></td><td></td><td></td><td></td><td>0.081<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td>(0.009)</td></tr>\n",
       "<tr><td style=\"text-align:left\">NumPlace</td><td></td><td></td><td>-1.146<sup>***</sup></td><td>-0.877<sup>***</sup></td><td>-0.642<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.241)</td><td>(0.232)</td><td>(0.232)</td></tr>\n",
       "<tr><td style=\"text-align:left\">catholic</td><td>2.180<sup>***</sup></td><td>1.118<sup>***</sup></td><td>1.084<sup>***</sup></td><td>-0.242<sup></sup></td><td>-0.432<sup>*</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.268)</td><td>(0.256)</td><td>(0.256)</td><td>(0.251)</td><td>(0.250)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_asian</td><td></td><td>4.883<sup>***</sup></td><td>4.842<sup>***</sup></td><td>4.471<sup>***</sup></td><td>4.317<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.503)</td><td>(0.502)</td><td>(0.484)</td><td>(0.482)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_black</td><td></td><td>-2.627<sup>***</sup></td><td>-2.680<sup>***</sup></td><td>-1.904<sup>***</sup></td><td>-1.986<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.442)</td><td>(0.442)</td><td>(0.426)</td><td>(0.424)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_hispanic</td><td></td><td>-0.027<sup></sup></td><td>-0.062<sup></sup></td><td>0.365<sup></sup></td><td>0.531<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.422)</td><td>(0.422)</td><td>(0.406)</td><td>(0.405)</td></tr>\n",
       "<tr><td style=\"text-align:left\">race_white</td><td></td><td>5.394<sup>***</sup></td><td>5.362<sup>***</sup></td><td>4.096<sup>***</sup></td><td>4.057<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.385)</td><td>(0.384)</td><td>(0.373)</td><td>(0.371)</td></tr>\n",
       "\n",
       "<td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>11078</td><td>11078</td><td>11078</td><td>11078</td><td>11078</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.006</td><td>0.106</td><td>0.108</td><td>0.172</td><td>0.181</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.006</td><td>0.106</td><td>0.108</td><td>0.172</td><td>0.181</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>9.686 (df=11076)</td><td>9.185 (df=11072)</td><td>9.176 (df=11071)</td><td>8.842 (df=11070)</td><td>8.793 (df=11068)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>66.096<sup>***</sup> (df=1; 11076)</td><td>263.634<sup>***</sup> (df=5; 11072)</td><td>223.910<sup>***</sup> (df=6; 11071)</td><td>328.655<sup>***</sup> (df=7; 11070)</td><td>272.289<sup>***</sup> (df=9; 11068)</td></tr>\n",
       "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"5\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x215f21642c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stargazer(gazer_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cleaned data, Going to a catholic school has a significant impact on the math score of students but the impact if nnot consistent(positive and negative) when we control for more variables. Though, the Model_4(controling for ``income``) the impact is not statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to drop all the NAs values(reducing significantly our dataset) but we'll have the same inconsistent impact effect of the Treatment(``Catholic``) onto the dependent variable(``Score_t``). This shows the real problem confounfing factors (``income`` or ``race``) have in biaising estimates.\n",
    "\n",
    "One has to make sure to find a way to account for these properly (in our case using a multivariate regression, but we cannot control all the existing confounders 😪) using for instance Randomized Control Trials, etc. : Here's a link to learn more about confounding in causal inference https://en.wikipedia.org/wiki/Confounding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
